{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dressed-irish",
   "metadata": {},
   "source": [
    "## Exercise 2.3 - Training the network\n",
    "\n",
    "Now that we have learnt how the dataset needs to be prepared and how to initialize the models - we get to the most exciting step: the training of the model. In this last part of the exercise, you will train the network and implement some methods to monitor and evaluate the training.\n",
    "\n",
    "First, we need some packages and methods from our scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invisible-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 20:51:56.483919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import clear_session\n",
    "\n",
    "# add folders data_processing and model to path so that we can read in our own modules from this folder\n",
    "sys.path.append(\"data_processing\")\n",
    "sys.path.append(\"model\")\n",
    "\n",
    "# import our own methods \n",
    "from load_datasets import load_train_dataset, load_test_dataset\n",
    "from model_setup import generator, discriminator\n",
    "from training_methods import train_step  # defined under model/training_methods.py \n",
    "from training_methods import eval_example_images  # defined under model/training_methods.py \n",
    "from visualize_data import plot_images_at_epoch  # defined under data_processinig/visualize_data.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf6cdc",
   "metadata": {},
   "source": [
    "Then we need to check which devices are available in our computer. If there are GPUs (better, faster and larger) use this device, else look for CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "precious-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# ask for GPU\n",
    "devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if len(devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(devices[0] ,enable=True)\n",
    "\n",
    "# if not there, ask for CPU\n",
    "else:\n",
    "    devices = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f859588",
   "metadata": {},
   "source": [
    "Now we load in the datasets in the same way we have done in exercise 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "laughing-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to project directory\n",
    "PROJECT_DIR = \"/net/merisi/pbigalke/teaching/METFUT2024/CGAN_Pix2Pix_MSG\"\n",
    "\n",
    "## path to train and val image sets\n",
    "TRAIN_PATH = f\"{PROJECT_DIR}/VIS_IR_images/train\"\n",
    "TEST_PATH = f\"{PROJECT_DIR}/VIS_IR_images/val\"\n",
    "\n",
    "# define image and batch size\n",
    "IMAGE_SIZE = 128  # do NOT change\n",
    "BATCH_SIZE = 10 \n",
    "\n",
    "# load training and test datasets\n",
    "train_dataset = load_train_dataset(TRAIN_PATH, BATCH_SIZE)\n",
    "test_dataset = load_test_dataset(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc84b4",
   "metadata": {},
   "source": [
    "### (a) Monitoring training procedure\n",
    "\n",
    "In the following we have already prepared a method that trains the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfdea235",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:19\u001b[0;36m\u001b[0m\n\u001b[0;31m    with open(loss_file_out, 'a') as csv_file:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# define training procedure\n",
    "def fit(generator, discriminator, gen_optimizer, discr_optimizer, train_dataset, test_dataset, epochs, \n",
    "        outpath_img, loss_file_out):\n",
    "\n",
    "    start_training = time.time()\n",
    "\n",
    "    # loop over number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # loop over batches in training dataset\n",
    "        for n, (ir_img, real_vis_img) in train_dataset.enumerate():\n",
    "            # perform training step\n",
    "             discr_loss, gen_total_loss, gen_gan_loss, gen_l1_loss = train_step(ir_img, real_vis_img, generator, discriminator, \n",
    "                                                                                gen_optimizer, discr_optimizer)\n",
    "\n",
    "        \n",
    "        # save losses to csv file\n",
    "        with open(loss_file_out, 'a') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow([epoch, n, discr_loss, gen_total_loss, gen_l1_loss])\n",
    "\n",
    "        ##### evaluate progress by plotting some example images\n",
    "\n",
    "        # select random images from test dataset\n",
    "        test_ir_img, test_fake_vis_img, test_real_vis_img = eval_example_images(test_dataset, generator, BATCH_SIZE)\n",
    "\n",
    "        \n",
    "        # select random image of batch\n",
    "        rand_idx = random.randint(0, batchsize-1)\n",
    "        ir_img = ir_batch.numpy()[rand_idx]\n",
    "        vis_img = vis_batch.numpy()[rand_idx]\n",
    "\n",
    "        \n",
    "        # save plot to\n",
    "        example_imgs = f\"{outpath_img}/example_images_epoch{epoch}.png\"\n",
    "        \n",
    "        ##### TODO \n",
    "        ##### plot all three test images in one plot: \n",
    "        ##### the infra-red image, the generated fake visible image and the real visible image\n",
    "        ##### Hint: look for inspiration in data_processing/visualize_data.py\n",
    "        plot_images_at_epoch(test_ir_img, test_fake_vis_img, test_real_vis_img, \n",
    "                            output_file=example_imgs, \n",
    "                            normalized=True)\n",
    "        #####\n",
    "                \n",
    "        # calculate the test and print it:\n",
    "        print(\"TODO: implement test loss, accuracy etc.\")\n",
    "        \n",
    "        # print some information on the progress of training\n",
    "        print(\"TODO: save losses in an array and return for later plotting\")\n",
    "        print(f\"Generator loss: {gen_loss:.2f}, Discriminator loss: {disc_loss:.2f}\")\n",
    "        print(f\"Time for epoch {epoch+1}: {(time.time()-start_epoch)/60.:.2f} min.\")\n",
    "        print(f\"Total runtime: {(time.time()-start_training)/60.:.2f} min.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cellular-tyler",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROJECT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# 150\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# path where to store example images\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m OUT_IMG \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mPROJECT_DIR\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/output/training_IR_VIS/example_images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(OUT_IMG):\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(OUT_IMG)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PROJECT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# define number of epochs (start with a low number e.g. 3 and once the code is done you can run the whole training)\n",
    "EPOCHS = 3  # 150\n",
    "\n",
    "# path where to store example images\n",
    "OUT_IMG = f\"{PROJECT_DIR}/output/training_IR_VIS/example_images\"\n",
    "if not os.path.exists(OUT_IMG):\n",
    "    os.makedirs(OUT_IMG)\n",
    "\n",
    "# file where to store losses\n",
    "LOSS_FILE = f\"{PROJECT_DIR}/output/training_IR_VIS/losses.csv\"\n",
    "with open(LOSS_FILE, 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    field = [\"epoch\", \"batch\", \"discr_loss\", \"gen_loss\", \"vis_similarity\"]\n",
    "    writer.writerow(field)\n",
    "\n",
    "# clear previous training session\n",
    "clear_session()\n",
    "\n",
    "# set up generator\n",
    "gen_model = generator()\n",
    "gen_model.summary()\n",
    "\n",
    "# set up discriminator\n",
    "discr_model = discriminator()\n",
    "discr_model.summary()\n",
    "\n",
    "# create optimizers for generator and discriminator\n",
    "gen_optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
    "discr_optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# train the model\n",
    "fit(gen_model, discr_model, gen_optimizer, discr_optimizer, train_dataset, test_dataset, EPOCHS, \n",
    "    outpath_img=OUT_IMG, loss_file_out=LOSS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f81c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
