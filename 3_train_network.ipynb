{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dressed-irish",
   "metadata": {},
   "source": [
    "# Image to Image Translation using Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "invisible-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "452d1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add folders data_processing and model to path so that we can read in our own modules from this folder\n",
    "sys.path.append(\"data_processing\")\n",
    "sys.path.append(\"model\")\n",
    "\n",
    "# import our own methods \n",
    "from load_datasets import load_train_dataset, load_test_dataset\n",
    "from model_setup import generator, discriminator\n",
    "from training_methods import train_step  # defined under model/training_methods.py \n",
    "from visualize_data import plot_images_at_epoch  # defined under data_processinig/visualize_data.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "precious-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.experimental.list_physical_devices(\"CPU\")\n",
    "print(devices)\n",
    "#tf.config.experimental.set_memory_growth(devices[0] ,enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "laughing-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128  # do NOT change\n",
    "\n",
    "# path to project directory\n",
    "PROJECT_DIR = \"/net/merisi/pbigalke/teaching/METFUT2024/CGAN_Pix2Pix_MSG\"\n",
    "\n",
    "## path to train and val image sets\n",
    "# DATASET_PATH = f\"{PROJECT_DIR}/VIS_IR_images\"\n",
    "TRAIN_PATH = f\"{PROJECT_DIR}/VIS_IR_images/train\"\n",
    "TEST_PATH = f\"{PROJECT_DIR}/VIS_IR_images/val\"\n",
    "\n",
    "# path where to store output\n",
    "OUT_PATH = f\"{PROJECT_DIR}/output/training_IR_VIS\"\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.makedirs(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elegant-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# load and preprocess dataset\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# get all training data\n",
    "train_dataset = load_train_dataset(TRAIN_PATH, BATCH_SIZE)\n",
    "print(train_dataset)\n",
    "\n",
    "# get all test data\n",
    "test_dataset = load_test_dataset(TEST_PATH, BATCH_SIZE)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "extended-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer (None, 128, 128, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 64, 64, 64)           1024      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 32, 32, 128)          131584    ['sequential[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)   (None, 16, 16, 256)          525312    ['sequential_1[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)   (None, 8, 8, 512)            2099200   ['sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 4, 4, 512)            4196352   ['sequential_3[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)   (None, 2, 2, 512)            4196352   ['sequential_4[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)   (None, 1, 1, 512)            4196352   ['sequential_5[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)   (None, 2, 2, 512)            4196352   ['sequential_6[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 2, 2, 1024)           0         ['sequential_7[0][0]',        \n",
      "                                                                     'sequential_5[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)   (None, 4, 4, 512)            8390656   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 4, 4, 1024)           0         ['sequential_8[0][0]',        \n",
      " )                                                                   'sequential_4[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)   (None, 8, 8, 512)            8390656   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 8, 8, 1024)           0         ['sequential_9[0][0]',        \n",
      " )                                                                   'sequential_3[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)  (None, 16, 16, 256)          4195328   ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 16, 16, 512)          0         ['sequential_10[0][0]',       \n",
      " )                                                                   'sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)  (None, 32, 32, 128)          1049088   ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 32, 32, 256)          0         ['sequential_11[0][0]',       \n",
      " )                                                                   'sequential_1[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)  (None, 64, 64, 64)           262400    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 64, 64, 128)          0         ['sequential_12[0][0]',       \n",
      " )                                                                   'sequential[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 128, 128, 1)          2049      ['concatenate_5[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41832705 (159.58 MB)\n",
      "Trainable params: 41823873 (159.55 MB)\n",
      "Non-trainable params: 8832 (34.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_image (InputLayer)    [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " target_image (InputLayer)   [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 128, 128, 2)          0         ['input_image[0][0]',         \n",
      " )                                                                   'target_image[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)  (None, 64, 64, 64)           2048      ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)  (None, 32, 32, 128)          131584    ['sequential_13[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)  (None, 16, 16, 256)          525312    ['sequential_14[0][0]']       \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, 18, 18, 256)          0         ['sequential_15[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 15, 15, 256)          1048576   ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 15, 15, 256)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, 17, 17, 256)          0         ['leaky_re_lu_10[0][0]']      \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 1)            4097      ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1711617 (6.53 MB)\n",
      "Trainable params: 1710849 (6.53 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "# set up generator\n",
    "gen_model = generator()\n",
    "gen_model.summary()\n",
    "\n",
    "# set up discriminator\n",
    "discr_model = discriminator()\n",
    "discr_model.summary()\n",
    "\n",
    "# create optimizers for generator and discriminator\n",
    "gen_optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
    "discr_optimizer = Adam(lr=2e-4, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfdea235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training procedure\n",
    "def fit(generator, discriminator, gen_optimizer, discr_optimizer, train_dataset, test_dataset, epochs, \n",
    "        outpath_img=None, outpath_model=None, save_after_epochs=5):\n",
    "\n",
    "    start_training = time.time()\n",
    "\n",
    "    # loop over number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        # loop over batches in training dataset\n",
    "        for n, (input_image, target) in train_dataset.enumerate():\n",
    "            # perform training step\n",
    "            gen_loss, disc_loss = train_step(input_image, target, generator, discriminator, \n",
    "                                             gen_optimizer, discr_optimizer)\n",
    "            \n",
    "        # save example images of this epoch\n",
    "        if outpath_img is not None:\n",
    "            # select random batch of test dataset\n",
    "            for ir_batch, vis_batch in test_dataset.take(1):\n",
    "\n",
    "                # predict vis img from ir with generator\n",
    "                predict_vis_batch = generator(ir_batch, training=True)\n",
    "\n",
    "                 # select random image of batch\n",
    "                rand_idx = random.randint(0, BATCH_SIZE-1)\n",
    "                ir_img = ir_batch.numpy()[rand_idx]\n",
    "                vis_img = vis_batch.numpy()[rand_idx]\n",
    "                predict_vis_img = predict_vis_batch.numpy()[rand_idx]\n",
    "\n",
    "                plot_images_at_epoch(ir_img, predict_vis_img, vis_img, \n",
    "                                    output_file=f\"{outpath_img}/example_images_epoch{epoch}_train.png\", \n",
    "                                    normalized=True)\n",
    "                \n",
    "                predict_vis_batch = generator(ir_batch, training=False)\n",
    "                predict_vis_img = predict_vis_batch.numpy()[rand_idx]\n",
    "                plot_images_at_epoch(ir_img, predict_vis_img, vis_img, \n",
    "                                    output_file=f\"{outpath_img}/example_images_epoch{epoch}_NOtrain.png\", \n",
    "                                    normalized=True)\n",
    "                \n",
    "        # save model state\n",
    "        if epoch % save_after_epochs == 0:\n",
    "            print(\"TODO: implement saving of model\")\n",
    "\n",
    "        # calculate the test and print it:\n",
    "        print(\"TODO: implement test loss, accuracy etc.\")\n",
    "        \n",
    "        # print some information on the progress of training\n",
    "        print(\"TODO: save losses in an array and return for later plotting\")\n",
    "        print(f\"Generator loss: {gen_loss:.2f}, Discriminator loss: {disc_loss:.2f}\")\n",
    "        print(f\"Time for epoch {epoch+1}: {(time.time()-start_epoch)/60.:.2f} min.\")\n",
    "        print(f\"Total runtime: {(time.time()-start_training)/60.:.2f} min.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a9c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_at_epoch(ir_image, predict_image, vis_image, output_file=None, normalized=False):\n",
    "\n",
    "    vmin = -1 if normalized else 0\n",
    "    vmax = 1 if normalized else 255\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    display_list= [ir_image, predict_image, vis_image]\n",
    "    title = [\"IR image\", \"predicted VIS image\", \"true VIS image\"]\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i], cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "        plt.axis(\"off\")\n",
    "    # save image if output file is defined\n",
    "    if output_file is not None:\n",
    "        plt.savefig(output_file, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cellular-tyler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9998462 -0.99640137\n",
      "-0.99996924 -0.99215686\n",
      "-0.7846868 0.7026362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do the training\n",
    "epochs = 1\n",
    "outpath_img = f\"{OUT_PATH}/example_images\"\n",
    "if not os.path.exists(outpath_img):\n",
    "    os.makedirs(outpath_img)\n",
    "outpath_model = f\"{OUT_PATH}/model_states\"\n",
    "if not os.path.exists(outpath_model):\n",
    "    os.makedirs(outpath_model)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# select random batch of test dataset\n",
    "for ir_batch, vis_batch in test_dataset.take(1):\n",
    "\n",
    "    # predict vis img from ir with generator\n",
    "    predict_vis_batch = gen_model(ir_batch, training=True)\n",
    "\n",
    "        # select random image of batch\n",
    "    rand_idx = random.randint(0, BATCH_SIZE-1)\n",
    "    ir_img = ir_batch.numpy()[rand_idx]\n",
    "    vis_img = vis_batch.numpy()[rand_idx]\n",
    "    predict_vis_img = predict_vis_batch.numpy()[rand_idx]\n",
    "\n",
    "    print(np.min(ir_img), np.max(ir_img))\n",
    "    print(np.min(vis_img), np.max(vis_img))\n",
    "    print(np.min(predict_vis_img), np.max(predict_vis_img))\n",
    "    print()\n",
    "\n",
    "    #plot_images_at_epoch(ir_img, predict_vis_img, vis_img, \n",
    "    #                    output_file=f\"{outpath_img}/example_images_epoch0_train.png\", \n",
    "    #                    normalized=True)\n",
    "                \n",
    "\n",
    "#fit(gen_model, discr_model, gen_optimizer, discr_optimizer, train_dataset, test_dataset, epochs, \n",
    "#    outpath_img=outpath_img, outpath_model=outpath_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
